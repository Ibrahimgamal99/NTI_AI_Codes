{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1937</td>\n",
       "      <td>14.2</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>vw rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1795</td>\n",
       "      <td>17.4</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>honda civic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>3613</td>\n",
       "      <td>16.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite sebring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>23.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>125</td>\n",
       "      <td>3900</td>\n",
       "      <td>17.4</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>cadillac eldorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>27.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>80</td>\n",
       "      <td>2670</td>\n",
       "      <td>15.0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>amc spirit dl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement horsepower  weight  acceleration  \\\n",
       "197  29.0          4          90.0         70    1937          14.2   \n",
       "198  33.0          4          91.0         53    1795          17.4   \n",
       "135  18.0          6         225.0        105    3613          16.5   \n",
       "298  23.0          8         350.0        125    3900          17.4   \n",
       "296  27.4          4         121.0         80    2670          15.0   \n",
       "\n",
       "     model year  origin                    car name  \n",
       "197          76       2                   vw rabbit  \n",
       "198          76       3                 honda civic  \n",
       "135          74       1  plymouth satellite sebring  \n",
       "298          79       1           cadillac eldorado  \n",
       "296          79       1               amc spirit dl  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('auto-mpg.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop\n",
    "df=df[df[\"horsepower\"].str.contains('?',regex=False) == False]\n",
    "df[\"horsepower\"]=pd.to_numeric(df[\"horsepower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',\n",
      "       'model year', 'origin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,1:-1]\n",
    "y=df.iloc[:,0]\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128,input_dim=7,activation='ReLU'))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(1))#output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1024      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,545\n",
      "Trainable params: 1,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_absolute_error',metrics='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "34/34 [==============================] - 1s 9ms/step - loss: 22.9886 - mae: 22.9886 - val_loss: 22.1925 - val_mae: 22.1925\n",
      "Epoch 2/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 20.9142 - mae: 20.9142 - val_loss: 18.9209 - val_mae: 18.9209\n",
      "Epoch 3/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 15.8598 - mae: 15.8598 - val_loss: 12.2454 - val_mae: 12.2454\n",
      "Epoch 4/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 10.0945 - mae: 10.0945 - val_loss: 8.8635 - val_mae: 8.8635\n",
      "Epoch 5/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7.8939 - mae: 7.8939 - val_loss: 6.9605 - val_mae: 6.9605\n",
      "Epoch 6/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6.5021 - mae: 6.5021 - val_loss: 5.6071 - val_mae: 5.6071\n",
      "Epoch 7/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5.2439 - mae: 5.2439 - val_loss: 4.6001 - val_mae: 4.6001\n",
      "Epoch 8/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4.4357 - mae: 4.4357 - val_loss: 4.0272 - val_mae: 4.0272\n",
      "Epoch 9/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4.0891 - mae: 4.0891 - val_loss: 3.7677 - val_mae: 3.7677\n",
      "Epoch 10/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3.9536 - mae: 3.9536 - val_loss: 3.6600 - val_mae: 3.6600\n",
      "Epoch 11/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.8411 - mae: 3.8411 - val_loss: 3.5233 - val_mae: 3.5233\n",
      "Epoch 12/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.7613 - mae: 3.7613 - val_loss: 3.4224 - val_mae: 3.4224\n",
      "Epoch 13/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.6686 - mae: 3.6686 - val_loss: 3.3821 - val_mae: 3.3821\n",
      "Epoch 14/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.5994 - mae: 3.5994 - val_loss: 3.2681 - val_mae: 3.2681\n",
      "Epoch 15/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3.5986 - mae: 3.5986 - val_loss: 3.3338 - val_mae: 3.3338\n",
      "Epoch 16/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.4276 - mae: 3.4276 - val_loss: 3.1720 - val_mae: 3.1720\n",
      "Epoch 17/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.4366 - mae: 3.4366 - val_loss: 3.0639 - val_mae: 3.0639\n",
      "Epoch 18/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.3397 - mae: 3.3397 - val_loss: 3.0432 - val_mae: 3.0432\n",
      "Epoch 19/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3.2589 - mae: 3.2589 - val_loss: 2.9634 - val_mae: 2.9634\n",
      "Epoch 20/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3.2071 - mae: 3.2071 - val_loss: 2.8957 - val_mae: 2.8957\n",
      "Epoch 21/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3.1244 - mae: 3.1244 - val_loss: 2.8247 - val_mae: 2.8247\n",
      "Epoch 22/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3.0661 - mae: 3.0661 - val_loss: 2.7695 - val_mae: 2.7695\n",
      "Epoch 23/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3.0068 - mae: 3.0068 - val_loss: 2.8022 - val_mae: 2.8022\n",
      "Epoch 24/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.9556 - mae: 2.9556 - val_loss: 2.6751 - val_mae: 2.6751\n",
      "Epoch 25/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.8897 - mae: 2.8897 - val_loss: 2.6005 - val_mae: 2.6005\n",
      "Epoch 26/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.8167 - mae: 2.8167 - val_loss: 2.5274 - val_mae: 2.5274\n",
      "Epoch 27/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.7848 - mae: 2.7848 - val_loss: 2.4936 - val_mae: 2.4936\n",
      "Epoch 28/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.7205 - mae: 2.7205 - val_loss: 2.4543 - val_mae: 2.4543\n",
      "Epoch 29/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.6697 - mae: 2.6697 - val_loss: 2.3961 - val_mae: 2.3961\n",
      "Epoch 30/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.6212 - mae: 2.6212 - val_loss: 2.3405 - val_mae: 2.3405\n",
      "Epoch 31/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.5951 - mae: 2.5951 - val_loss: 2.2934 - val_mae: 2.2934\n",
      "Epoch 32/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.5356 - mae: 2.5356 - val_loss: 2.2754 - val_mae: 2.2754\n",
      "Epoch 33/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.4686 - mae: 2.4686 - val_loss: 2.1983 - val_mae: 2.1983\n",
      "Epoch 34/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.4419 - mae: 2.4419 - val_loss: 2.2275 - val_mae: 2.2275\n",
      "Epoch 35/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.3913 - mae: 2.3913 - val_loss: 2.1307 - val_mae: 2.1307\n",
      "Epoch 36/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.3640 - mae: 2.3640 - val_loss: 2.1192 - val_mae: 2.1192\n",
      "Epoch 37/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.3482 - mae: 2.3482 - val_loss: 2.1209 - val_mae: 2.1209\n",
      "Epoch 38/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.3622 - mae: 2.3622 - val_loss: 2.0830 - val_mae: 2.0830\n",
      "Epoch 39/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.3009 - mae: 2.3009 - val_loss: 2.0029 - val_mae: 2.0029\n",
      "Epoch 40/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.2516 - mae: 2.2516 - val_loss: 1.9741 - val_mae: 1.9741\n",
      "Epoch 41/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.2546 - mae: 2.2546 - val_loss: 1.9252 - val_mae: 1.9252\n",
      "Epoch 42/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.2178 - mae: 2.2178 - val_loss: 1.9416 - val_mae: 1.9416\n",
      "Epoch 43/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.1742 - mae: 2.1742 - val_loss: 1.9498 - val_mae: 1.9498\n",
      "Epoch 44/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1784 - mae: 2.1784 - val_loss: 1.9612 - val_mae: 1.9612\n",
      "Epoch 45/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1641 - mae: 2.1641 - val_loss: 1.8607 - val_mae: 1.8607\n",
      "Epoch 46/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.1467 - mae: 2.1467 - val_loss: 1.9106 - val_mae: 1.9106\n",
      "Epoch 47/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.1262 - mae: 2.1262 - val_loss: 1.8467 - val_mae: 1.8467\n",
      "Epoch 48/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1344 - mae: 2.1344 - val_loss: 1.8430 - val_mae: 1.8430\n",
      "Epoch 49/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1152 - mae: 2.1152 - val_loss: 1.9000 - val_mae: 1.9000\n",
      "Epoch 50/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1898 - mae: 2.1898 - val_loss: 1.8433 - val_mae: 1.8433\n",
      "Epoch 51/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1185 - mae: 2.1185 - val_loss: 1.8769 - val_mae: 1.8769\n",
      "Epoch 52/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.1156 - mae: 2.1156 - val_loss: 1.8761 - val_mae: 1.8761\n",
      "Epoch 53/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0919 - mae: 2.0919 - val_loss: 1.8190 - val_mae: 1.8190\n",
      "Epoch 54/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0906 - mae: 2.0906 - val_loss: 1.8052 - val_mae: 1.8052\n",
      "Epoch 55/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0911 - mae: 2.0911 - val_loss: 1.8264 - val_mae: 1.8264\n",
      "Epoch 56/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0875 - mae: 2.0875 - val_loss: 1.7988 - val_mae: 1.7988\n",
      "Epoch 57/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0737 - mae: 2.0737 - val_loss: 1.8160 - val_mae: 1.8160\n",
      "Epoch 58/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0972 - mae: 2.0972 - val_loss: 1.8039 - val_mae: 1.8039\n",
      "Epoch 59/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.1647 - mae: 2.1647 - val_loss: 1.8938 - val_mae: 1.8938\n",
      "Epoch 60/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1059 - mae: 2.1059 - val_loss: 1.7987 - val_mae: 1.7987\n",
      "Epoch 61/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0749 - mae: 2.0749 - val_loss: 1.7616 - val_mae: 1.7616\n",
      "Epoch 62/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0586 - mae: 2.0586 - val_loss: 1.7957 - val_mae: 1.7957\n",
      "Epoch 63/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0719 - mae: 2.0719 - val_loss: 1.7873 - val_mae: 1.7873\n",
      "Epoch 64/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0608 - mae: 2.0608 - val_loss: 1.8457 - val_mae: 1.8457\n",
      "Epoch 65/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0825 - mae: 2.0825 - val_loss: 1.7813 - val_mae: 1.7813\n",
      "Epoch 66/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0426 - mae: 2.0426 - val_loss: 1.7834 - val_mae: 1.7834\n",
      "Epoch 67/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0685 - mae: 2.0685 - val_loss: 1.8131 - val_mae: 1.8131\n",
      "Epoch 68/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0611 - mae: 2.0611 - val_loss: 1.7868 - val_mae: 1.7868\n",
      "Epoch 69/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0660 - mae: 2.0660 - val_loss: 1.8058 - val_mae: 1.8058\n",
      "Epoch 70/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0757 - mae: 2.0757 - val_loss: 1.7869 - val_mae: 1.7869\n",
      "Epoch 71/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0657 - mae: 2.0657 - val_loss: 1.7642 - val_mae: 1.7642\n",
      "Epoch 72/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0412 - mae: 2.0412 - val_loss: 1.7533 - val_mae: 1.7533\n",
      "Epoch 73/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0425 - mae: 2.0425 - val_loss: 1.7703 - val_mae: 1.7703\n",
      "Epoch 74/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0486 - mae: 2.0486 - val_loss: 1.8400 - val_mae: 1.8400\n",
      "Epoch 75/128\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2.1265 - mae: 2.1265 - val_loss: 2.0239 - val_mae: 2.0239\n",
      "Epoch 76/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0930 - mae: 2.0930 - val_loss: 1.7602 - val_mae: 1.7602\n",
      "Epoch 77/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0765 - mae: 2.0765 - val_loss: 1.7541 - val_mae: 1.7541\n",
      "Epoch 78/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0496 - mae: 2.0496 - val_loss: 1.7830 - val_mae: 1.7830\n",
      "Epoch 79/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0694 - mae: 2.0694 - val_loss: 1.7239 - val_mae: 1.7239\n",
      "Epoch 80/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0381 - mae: 2.0381 - val_loss: 1.7713 - val_mae: 1.7713\n",
      "Epoch 81/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0533 - mae: 2.0533 - val_loss: 1.7798 - val_mae: 1.7798\n",
      "Epoch 82/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0402 - mae: 2.0402 - val_loss: 1.7614 - val_mae: 1.7614\n",
      "Epoch 83/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0753 - mae: 2.0753 - val_loss: 1.7598 - val_mae: 1.7598\n",
      "Epoch 84/128\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2.0441 - mae: 2.0441 - val_loss: 1.8269 - val_mae: 1.8269\n",
      "Epoch 85/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0527 - mae: 2.0527 - val_loss: 1.7416 - val_mae: 1.7416\n",
      "Epoch 86/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0186 - mae: 2.0186 - val_loss: 1.7826 - val_mae: 1.7826\n",
      "Epoch 87/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0439 - mae: 2.0439 - val_loss: 1.7638 - val_mae: 1.7638\n",
      "Epoch 88/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0468 - mae: 2.0468 - val_loss: 1.7740 - val_mae: 1.7740\n",
      "Epoch 89/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0293 - mae: 2.0293 - val_loss: 1.7649 - val_mae: 1.7649\n",
      "Epoch 90/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0163 - mae: 2.0163 - val_loss: 1.7370 - val_mae: 1.7370\n",
      "Epoch 91/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0402 - mae: 2.0402 - val_loss: 1.8256 - val_mae: 1.8256\n",
      "Epoch 92/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0563 - mae: 2.0563 - val_loss: 1.7352 - val_mae: 1.7352\n",
      "Epoch 93/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0724 - mae: 2.0724 - val_loss: 1.7459 - val_mae: 1.7459\n",
      "Epoch 94/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0369 - mae: 2.0369 - val_loss: 1.8203 - val_mae: 1.8203\n",
      "Epoch 95/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0672 - mae: 2.0672 - val_loss: 1.7399 - val_mae: 1.7399\n",
      "Epoch 96/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0074 - mae: 2.0074 - val_loss: 1.7194 - val_mae: 1.7194\n",
      "Epoch 97/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0084 - mae: 2.0084 - val_loss: 1.9127 - val_mae: 1.9127\n",
      "Epoch 98/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.1282 - mae: 2.1282 - val_loss: 1.7722 - val_mae: 1.7722\n",
      "Epoch 99/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0444 - mae: 2.0444 - val_loss: 1.7431 - val_mae: 1.7431\n",
      "Epoch 100/128\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2.0301 - mae: 2.0301 - val_loss: 1.6874 - val_mae: 1.6874\n",
      "Epoch 101/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0313 - mae: 2.0313 - val_loss: 1.8856 - val_mae: 1.8856\n",
      "Epoch 102/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0950 - mae: 2.0950 - val_loss: 1.8004 - val_mae: 1.8004\n",
      "Epoch 103/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0024 - mae: 2.0024 - val_loss: 1.8288 - val_mae: 1.8288\n",
      "Epoch 104/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.1157 - mae: 2.1157 - val_loss: 1.9158 - val_mae: 1.9158\n",
      "Epoch 105/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0149 - mae: 2.0149 - val_loss: 1.7529 - val_mae: 1.7529\n",
      "Epoch 106/128\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2.0090 - mae: 2.0090 - val_loss: 1.7050 - val_mae: 1.7050\n",
      "Epoch 107/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0282 - mae: 2.0282 - val_loss: 1.7368 - val_mae: 1.7368\n",
      "Epoch 108/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0042 - mae: 2.0042 - val_loss: 1.7251 - val_mae: 1.7251\n",
      "Epoch 109/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0113 - mae: 2.0113 - val_loss: 1.7389 - val_mae: 1.7389\n",
      "Epoch 110/128\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.9989 - mae: 1.9989 - val_loss: 1.7025 - val_mae: 1.7025\n",
      "Epoch 111/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0206 - mae: 2.0206 - val_loss: 1.7331 - val_mae: 1.7331\n",
      "Epoch 112/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.9922 - mae: 1.9922 - val_loss: 1.7091 - val_mae: 1.7091\n",
      "Epoch 113/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.9992 - mae: 1.9992 - val_loss: 1.7294 - val_mae: 1.7294\n",
      "Epoch 114/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0156 - mae: 2.0156 - val_loss: 1.7365 - val_mae: 1.7365\n",
      "Epoch 115/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0001 - mae: 2.0001 - val_loss: 1.7171 - val_mae: 1.7171\n",
      "Epoch 116/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0057 - mae: 2.0057 - val_loss: 1.8078 - val_mae: 1.8078\n",
      "Epoch 117/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0150 - mae: 2.0150 - val_loss: 1.7118 - val_mae: 1.7118\n",
      "Epoch 118/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2.0051 - mae: 2.0051 - val_loss: 1.7121 - val_mae: 1.7121\n",
      "Epoch 119/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0479 - mae: 2.0479 - val_loss: 1.7405 - val_mae: 1.7405\n",
      "Epoch 120/128\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2.0035 - mae: 2.0035 - val_loss: 1.7658 - val_mae: 1.7658\n",
      "Epoch 121/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0130 - mae: 2.0130 - val_loss: 1.7140 - val_mae: 1.7140\n",
      "Epoch 122/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0184 - mae: 2.0184 - val_loss: 1.7694 - val_mae: 1.7694\n",
      "Epoch 123/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1.9819 - mae: 1.9819 - val_loss: 1.6937 - val_mae: 1.6937\n",
      "Epoch 124/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0063 - mae: 2.0063 - val_loss: 1.7456 - val_mae: 1.7456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0055 - mae: 2.0055 - val_loss: 1.6981 - val_mae: 1.6981\n",
      "Epoch 126/128\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1.9842 - mae: 1.9842 - val_loss: 1.7478 - val_mae: 1.7478\n",
      "Epoch 127/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.9955 - mae: 1.9955 - val_loss: 1.7499 - val_mae: 1.7499\n",
      "Epoch 128/128\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0090 - mae: 2.0090 - val_loss: 1.7552 - val_mae: 1.7552\n"
     ]
    }
   ],
   "source": [
    "res=model.fit(X_train, y_train, validation_data=(X_test,y_test),batch_size = 10, epochs = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score =  0.901838897956551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"r2_score = \",r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f11740bd2b0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res.history['loss'])\n",
    "plt.plot(res.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
